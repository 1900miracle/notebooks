{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing using Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> “In God we trust. All others must bring data.” – W. Edwards Deming, statistician"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "\n",
    "### What?\n",
    "Convert words to vectors in a high dimensional space. Each dimension denotes an aspect like gender, type of object / word.\n",
    "\n",
    "\"Word embeddings\" are a family of natural language processing techniques aiming at mapping semantic meaning into a geometric space. This is done by associating a numeric vector to every word in a dictionary, such that the distance (e.g. L2 distance or more commonly cosine distance) between any two vectors would capture part of the semantic relationship between the two associated words. The geometric space formed by these vectors is called an embedding space.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why?\n",
    "By converting words to vectors we build relations between words. More similar the words in a dimension, more closer their scores are.\n",
    "\n",
    "### Example\n",
    "_W(green) = (1.2, 0.98, 0.05, ...)_\n",
    "\n",
    "_W(red) = (1.1, 0.2, 0.5, ...)_\n",
    "\n",
    "Here the vector values of _green_ and _red_ are very similar in one dimension because they both are colours. The value for second dimension is very different because red might be depicting something negative in the training data while green is used for positiveness.\n",
    "\n",
    "By vectorizing we are indirectly building different kind of relations between words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of `word2vec` using gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading blog post from data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = os.path.join(os.path.abspath(os.path.curdir), '..', \n",
    "                              'data', 'word_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_posts = []\n",
    "female_post = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIRECTORY,\"male_blog_list.txt\"),\"rb\") as male_file:\n",
    "    male_posts= pickle.load(male_file)\n",
    "    \n",
    "with open(os.path.join(DATA_DIRECTORY,\"female_blog_list.txt\"),\"rb\") as female_file:\n",
    "    female_posts = pickle.load(female_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252\n",
      "2611\n"
     ]
    }
   ],
   "source": [
    "print(len(female_posts))\n",
    "print(len(male_posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_male_posts = list(filter(lambda p: len(p) > 0, male_posts))\n",
    "filtered_female_posts = list(filter(lambda p: len(p) > 0, female_posts))\n",
    "posts = filtered_female_posts + filtered_male_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2247 2595 4842\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_female_posts), len(filtered_male_posts), len(posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(size=200, min_count=1)\n",
    "w2v.build_vocab(map(lambda x: x.split(), posts[:100]), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.0017214040437083416"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.similarity('I', 'My')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've tried starting blog after blog and it just never feels right.  Then I read today that it feels strange to most people, but the more you do it the better it gets (hmm, sounds suspiciously like something else!) so I decided to give it another try.    My husband bought me a notepad at  urlLink McNally  (the best bookstore in Western Canada) with that title and a picture of a 50s housewife grinning desperately.  Each page has something funny like \"New curtains!  Hurrah!\".  For some reason it struck me as absolutely hilarious and has stuck in my head ever since.  What were those women thinking?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.5/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.0081163338784362837"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(posts[5])\n",
    "w2v.similarity('ring', 'husband')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.015692758390509903"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.similarity('ring', 'housewife')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.033483647840445246"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.similarity('women', 'housewife')  # Diversity friendly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec\n",
    "\n",
    "The same technique of word2vec is extrapolated to documents. Here, we do everything done in word2vec + we vectorize the documents too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 for male, 1 for female\n",
    "y_posts = np.concatenate((np.zeros(len(filtered_male_posts)),\n",
    "                          np.ones(len(filtered_female_posts))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4842"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks for Sentence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train convolutional network for sentiment analysis. \n",
    "\n",
    "Based on\n",
    "\"Convolutional Neural Networks for Sentence Classification\" by Yoon Kim\n",
    "http://arxiv.org/pdf/1408.5882v2.pdf\n",
    "\n",
    "For 'CNN-non-static' gets to 82.1% after 61 epochs with following settings:\n",
    "embedding_dim = 20          \n",
    "filter_sizes = (3, 4)\n",
    "num_filters = 3\n",
    "dropout_prob = (0.7, 0.8)\n",
    "hidden_dims = 100\n",
    "\n",
    "For 'CNN-rand' gets to 78-79% after 7-8 epochs with following settings:\n",
    "embedding_dim = 20          \n",
    "filter_sizes = (3, 4)\n",
    "num_filters = 150\n",
    "dropout_prob = (0.25, 0.5)\n",
    "hidden_dims = 150\n",
    "\n",
    "For 'CNN-static' gets to 75.4% after 7 epochs with following settings:\n",
    "embedding_dim = 100          \n",
    "filter_sizes = (3, 4)\n",
    "num_filters = 150\n",
    "dropout_prob = (0.25, 0.5)\n",
    "hidden_dims = 150\n",
    "\n",
    "* it turns out that such a small data set as \"Movie reviews with one\n",
    "sentence per review\"  (Pang and Lee, 2005) requires much smaller network\n",
    "than the one introduced in the original article:\n",
    "- embedding dimension is only 20 (instead of 300; 'CNN-static' still requires ~100)\n",
    "- 2 filter sizes (instead of 3)\n",
    "- higher dropout probabilities and\n",
    "- 3 filters per filter size is enough for 'CNN-non-static' (instead of 100)\n",
    "- embedding initialization does not require prebuilt Google Word2Vec data.\n",
    "Training Word2Vec on the same \"Movie reviews\" data set is enough to \n",
    "achieve performance reported in the article (81.6%)\n",
    "\n",
    "** Another distinct difference is slidind MaxPooling window of length=2\n",
    "instead of MaxPooling over whole feature map as in the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import word_embedding\n",
    "from word2vec import train_word2vec\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import (Activation, Dense, Dropout, Embedding, \n",
    "                          Flatten, Input, \n",
    "                          Conv1D, MaxPooling1D)\n",
    "from keras.layers.merge import Concatenate\n",
    "\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "Model Variations. See Kim Yoon's Convolutional Neural Networks for \n",
    "Sentence Classification, Section 3 for detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model variation is CNN-rand\n"
     ]
    }
   ],
   "source": [
    "model_variation = 'CNN-rand'  #  CNN-rand | CNN-non-static | CNN-static\n",
    "print('Model variation is %s' % model_variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Hyperparameters\n",
    "sequence_length = 56\n",
    "embedding_dim = 20          \n",
    "filter_sizes = (3, 4)\n",
    "num_filters = 150\n",
    "dropout_prob = (0.25, 0.5)\n",
    "hidden_dims = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "val_split = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec parameters, see train_word2vec\n",
    "min_word_count = 1  # Minimum word count                        \n",
    "context = 10        # Context window size    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "x, y, vocabulary, vocabulary_inv = word_embedding.load_data()\n",
    "\n",
    "if model_variation=='CNN-non-static' or model_variation=='CNN-static':\n",
    "    embedding_weights = train_word2vec(x, vocabulary_inv, \n",
    "                                       embedding_dim, min_word_count, \n",
    "                                       context)\n",
    "    if model_variation=='CNN-static':\n",
    "        x = embedding_weights[0][x]\n",
    "elif model_variation=='CNN-rand':\n",
    "    embedding_weights = None\n",
    "else:\n",
    "    raise ValueError('Unknown model variation')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = x[shuffle_indices]\n",
    "y_shuffled = y[shuffle_indices].argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 18765\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary Size: {:d}\".format(len(vocabulary)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(padding=\"valid\", activation=\"relu\", filters=150, strides=1, kernel_size=3)`\n",
      "  \n",
      "/srv/venv/lib/python3.5/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  if __name__ == '__main__':\n",
      "/srv/venv/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(padding=\"valid\", activation=\"relu\", filters=150, strides=1, kernel_size=4)`\n",
      "  \n",
      "/srv/venv/lib/python3.5/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    }
   ],
   "source": [
    "graph_in = Input(shape=(sequence_length, embedding_dim))\n",
    "convs = []\n",
    "for fsz in filter_sizes:\n",
    "    conv = Conv1D(filters=num_filters,\n",
    "                  filter_length=fsz,\n",
    "                  padding='valid',\n",
    "                  activation='relu',\n",
    "                  strides=1)(graph_in)\n",
    "    pool = MaxPooling1D(pool_length=2)(conv)\n",
    "    flatten = Flatten()(pool)\n",
    "    convs.append(flatten)\n",
    "    \n",
    "if len(filter_sizes)>1:\n",
    "    out = Concatenate()(convs)\n",
    "else:\n",
    "    out = convs[0]\n",
    "\n",
    "graph = Model(input=graph_in, output=out)\n",
    "\n",
    "# main sequential model\n",
    "model = Sequential()\n",
    "if not model_variation=='CNN-static':\n",
    "    model.add(Embedding(len(vocabulary), embedding_dim, input_length=sequence_length,\n",
    "                        weights=embedding_weights))\n",
    "model.add(Dropout(dropout_prob[0], input_shape=(sequence_length, embedding_dim)))\n",
    "model.add(graph)\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(dropout_prob[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.5/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9595 samples, validate on 1067 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 0.6496 - acc: 0.6049 - val_loss: 0.5656 - val_acc: 0.7160\n",
      "Epoch 2/100\n",
      " - 6s - loss: 0.4559 - acc: 0.7921 - val_loss: 0.5143 - val_acc: 0.7563\n",
      "Epoch 3/100\n",
      " - 6s - loss: 0.3546 - acc: 0.8493 - val_loss: 0.5100 - val_acc: 0.7741\n",
      "Epoch 4/100\n",
      " - 6s - loss: 0.2938 - acc: 0.8795 - val_loss: 0.5208 - val_acc: 0.7713\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.2418 - acc: 0.9030 - val_loss: 0.5642 - val_acc: 0.7798\n",
      "Epoch 6/100\n",
      " - 6s - loss: 0.1969 - acc: 0.9260 - val_loss: 0.6212 - val_acc: 0.7788\n",
      "Epoch 7/100\n",
      " - 6s - loss: 0.1563 - acc: 0.9378 - val_loss: 0.6965 - val_acc: 0.7423\n",
      "Epoch 8/100\n",
      " - 6s - loss: 0.1278 - acc: 0.9530 - val_loss: 0.7444 - val_acc: 0.7610\n",
      "Epoch 9/100\n",
      " - 6s - loss: 0.1027 - acc: 0.9622 - val_loss: 0.8164 - val_acc: 0.7610\n",
      "Epoch 10/100\n",
      " - 6s - loss: 0.0739 - acc: 0.9732 - val_loss: 0.9005 - val_acc: 0.7488\n",
      "Epoch 11/100\n",
      " - 5s - loss: 0.0593 - acc: 0.9783 - val_loss: 1.0114 - val_acc: 0.7563\n",
      "Epoch 12/100\n",
      " - 5s - loss: 0.0422 - acc: 0.9847 - val_loss: 1.2408 - val_acc: 0.7451\n",
      "Epoch 13/100\n",
      " - 6s - loss: 0.0344 - acc: 0.9874 - val_loss: 1.5673 - val_acc: 0.7254\n",
      "Epoch 14/100\n",
      " - 6s - loss: 0.0243 - acc: 0.9908 - val_loss: 1.6152 - val_acc: 0.7404\n",
      "Epoch 15/100\n",
      " - 6s - loss: 0.0231 - acc: 0.9927 - val_loss: 1.5456 - val_acc: 0.7516\n",
      "Epoch 16/100\n",
      " - 6s - loss: 0.0152 - acc: 0.9951 - val_loss: 1.7031 - val_acc: 0.7526\n",
      "Epoch 17/100\n",
      " - 6s - loss: 0.0131 - acc: 0.9954 - val_loss: 1.7531 - val_acc: 0.7423\n",
      "Epoch 18/100\n",
      " - 6s - loss: 0.0109 - acc: 0.9965 - val_loss: 1.9930 - val_acc: 0.7376\n",
      "Epoch 19/100\n",
      " - 6s - loss: 0.0115 - acc: 0.9967 - val_loss: 1.9948 - val_acc: 0.7385\n",
      "Epoch 20/100\n",
      " - 6s - loss: 0.0062 - acc: 0.9983 - val_loss: 2.2219 - val_acc: 0.7413\n",
      "Epoch 21/100\n",
      " - 6s - loss: 0.0100 - acc: 0.9977 - val_loss: 2.3438 - val_acc: 0.7329\n",
      "Epoch 22/100\n",
      " - 6s - loss: 0.0061 - acc: 0.9985 - val_loss: 2.2392 - val_acc: 0.7441\n",
      "Epoch 23/100\n",
      " - 6s - loss: 0.0068 - acc: 0.9981 - val_loss: 2.2838 - val_acc: 0.7526\n",
      "Epoch 24/100\n",
      " - 6s - loss: 0.0067 - acc: 0.9985 - val_loss: 2.4086 - val_acc: 0.7460\n",
      "Epoch 25/100\n",
      " - 5s - loss: 0.0061 - acc: 0.9976 - val_loss: 2.3504 - val_acc: 0.7451\n",
      "Epoch 26/100\n",
      " - 5s - loss: 0.0064 - acc: 0.9981 - val_loss: 2.3536 - val_acc: 0.7460\n",
      "Epoch 27/100\n",
      " - 6s - loss: 0.0069 - acc: 0.9982 - val_loss: 2.3395 - val_acc: 0.7470\n",
      "Epoch 28/100\n",
      " - 6s - loss: 0.0039 - acc: 0.9991 - val_loss: 2.4799 - val_acc: 0.7423\n",
      "Epoch 29/100\n",
      " - 6s - loss: 0.0052 - acc: 0.9990 - val_loss: 2.3749 - val_acc: 0.7460\n",
      "Epoch 30/100\n",
      " - 6s - loss: 0.0058 - acc: 0.9989 - val_loss: 2.4572 - val_acc: 0.7460\n",
      "Epoch 31/100\n",
      " - 6s - loss: 0.0061 - acc: 0.9984 - val_loss: 2.5578 - val_acc: 0.7423\n",
      "Epoch 32/100\n",
      " - 6s - loss: 0.0034 - acc: 0.9992 - val_loss: 2.5429 - val_acc: 0.7404\n",
      "Epoch 33/100\n",
      " - 6s - loss: 0.0025 - acc: 0.9992 - val_loss: 2.5779 - val_acc: 0.7432\n",
      "Epoch 34/100\n",
      " - 5s - loss: 0.0050 - acc: 0.9992 - val_loss: 2.5741 - val_acc: 0.7460\n",
      "Epoch 35/100\n",
      " - 5s - loss: 0.0030 - acc: 0.9989 - val_loss: 2.6113 - val_acc: 0.7460\n",
      "Epoch 36/100\n",
      " - 6s - loss: 0.0029 - acc: 0.9995 - val_loss: 2.5993 - val_acc: 0.7498\n",
      "Epoch 37/100\n",
      " - 6s - loss: 0.0017 - acc: 0.9995 - val_loss: 2.6917 - val_acc: 0.7526\n",
      "Epoch 38/100\n",
      " - 6s - loss: 0.0041 - acc: 0.9991 - val_loss: 2.6745 - val_acc: 0.7507\n",
      "Epoch 39/100\n",
      " - 6s - loss: 0.0045 - acc: 0.9991 - val_loss: 2.7544 - val_acc: 0.7451\n",
      "Epoch 40/100\n",
      " - 6s - loss: 0.0039 - acc: 0.9991 - val_loss: 2.7988 - val_acc: 0.7488\n",
      "Epoch 41/100\n",
      " - 6s - loss: 0.0017 - acc: 0.9994 - val_loss: 2.7560 - val_acc: 0.7526\n",
      "Epoch 42/100\n",
      " - 6s - loss: 0.0022 - acc: 0.9994 - val_loss: 2.7658 - val_acc: 0.7423\n",
      "Epoch 43/100\n",
      " - 6s - loss: 0.0046 - acc: 0.9992 - val_loss: 2.8164 - val_acc: 0.7441\n",
      "Epoch 44/100\n",
      " - 6s - loss: 0.0024 - acc: 0.9996 - val_loss: 2.8882 - val_acc: 0.7451\n",
      "Epoch 45/100\n",
      " - 5s - loss: 0.0030 - acc: 0.9995 - val_loss: 2.8779 - val_acc: 0.7451\n",
      "Epoch 46/100\n",
      " - 5s - loss: 0.0020 - acc: 0.9997 - val_loss: 2.9367 - val_acc: 0.7479\n",
      "Epoch 47/100\n",
      " - 5s - loss: 0.0070 - acc: 0.9986 - val_loss: 2.8116 - val_acc: 0.7488\n",
      "Epoch 48/100\n",
      " - 5s - loss: 0.0018 - acc: 0.9995 - val_loss: 2.9610 - val_acc: 0.7413\n",
      "Epoch 49/100\n",
      " - 5s - loss: 0.0033 - acc: 0.9991 - val_loss: 2.8903 - val_acc: 0.7441\n",
      "Epoch 50/100\n",
      " - 6s - loss: 0.0027 - acc: 0.9995 - val_loss: 2.9352 - val_acc: 0.7470\n",
      "Epoch 51/100\n",
      " - 6s - loss: 0.0035 - acc: 0.9993 - val_loss: 3.0395 - val_acc: 0.7479\n",
      "Epoch 52/100\n",
      " - 6s - loss: 0.0019 - acc: 0.9996 - val_loss: 2.9245 - val_acc: 0.7507\n",
      "Epoch 53/100\n",
      " - 6s - loss: 0.0025 - acc: 0.9997 - val_loss: 2.9744 - val_acc: 0.7507\n",
      "Epoch 54/100\n",
      " - 6s - loss: 0.0062 - acc: 0.9989 - val_loss: 2.9340 - val_acc: 0.7479\n",
      "Epoch 55/100\n",
      " - 6s - loss: 0.0016 - acc: 0.9997 - val_loss: 3.0473 - val_acc: 0.7451\n",
      "Epoch 56/100\n",
      " - 5s - loss: 0.0053 - acc: 0.9990 - val_loss: 3.1605 - val_acc: 0.7395\n",
      "Epoch 57/100\n",
      " - 6s - loss: 0.0041 - acc: 0.9991 - val_loss: 2.8168 - val_acc: 0.7488\n",
      "Epoch 58/100\n",
      " - 5s - loss: 0.0040 - acc: 0.9994 - val_loss: 2.8512 - val_acc: 0.7451\n",
      "Epoch 59/100\n",
      " - 6s - loss: 0.0043 - acc: 0.9992 - val_loss: 2.8770 - val_acc: 0.7432\n",
      "Epoch 60/100\n",
      " - 5s - loss: 0.0026 - acc: 0.9995 - val_loss: 2.8797 - val_acc: 0.7516\n",
      "Epoch 61/100\n",
      " - 5s - loss: 0.0020 - acc: 0.9997 - val_loss: 2.9994 - val_acc: 0.7498\n",
      "Epoch 62/100\n",
      " - 5s - loss: 0.0031 - acc: 0.9997 - val_loss: 2.9610 - val_acc: 0.7460\n",
      "Epoch 63/100\n",
      " - 6s - loss: 0.0037 - acc: 0.9995 - val_loss: 2.9939 - val_acc: 0.7516\n",
      "Epoch 64/100\n",
      " - 6s - loss: 0.0013 - acc: 0.9996 - val_loss: 3.0178 - val_acc: 0.7488\n",
      "Epoch 65/100\n",
      " - 6s - loss: 0.0031 - acc: 0.9995 - val_loss: 3.0454 - val_acc: 0.7479\n",
      "Epoch 66/100\n",
      " - 6s - loss: 0.0067 - acc: 0.9991 - val_loss: 2.9772 - val_acc: 0.7423\n",
      "Epoch 67/100\n",
      " - 6s - loss: 0.0031 - acc: 0.9995 - val_loss: 3.0261 - val_acc: 0.7488\n",
      "Epoch 68/100\n",
      " - 6s - loss: 0.0015 - acc: 0.9997 - val_loss: 3.1054 - val_acc: 0.7488\n",
      "Epoch 69/100\n",
      " - 6s - loss: 0.0029 - acc: 0.9994 - val_loss: 3.0240 - val_acc: 0.7479\n",
      "Epoch 70/100\n",
      " - 6s - loss: 0.0029 - acc: 0.9996 - val_loss: 3.0695 - val_acc: 0.7451\n",
      "Epoch 71/100\n",
      " - 6s - loss: 3.8876e-04 - acc: 0.9998 - val_loss: 3.0366 - val_acc: 0.7545\n",
      "Epoch 72/100\n",
      " - 6s - loss: 0.0046 - acc: 0.9994 - val_loss: 3.0739 - val_acc: 0.7563\n",
      "Epoch 73/100\n",
      " - 6s - loss: 9.2584e-04 - acc: 0.9998 - val_loss: 3.0656 - val_acc: 0.7451\n",
      "Epoch 74/100\n",
      " - 5s - loss: 0.0016 - acc: 0.9997 - val_loss: 3.0926 - val_acc: 0.7488\n",
      "Epoch 75/100\n",
      " - 5s - loss: 0.0026 - acc: 0.9996 - val_loss: 3.0581 - val_acc: 0.7488\n",
      "Epoch 76/100\n",
      " - 5s - loss: 0.0010 - acc: 0.9998 - val_loss: 3.0963 - val_acc: 0.7470\n",
      "Epoch 77/100\n",
      " - 5s - loss: 0.0042 - acc: 0.9993 - val_loss: 3.1445 - val_acc: 0.7488\n",
      "Epoch 78/100\n",
      " - 5s - loss: 2.8347e-04 - acc: 0.9999 - val_loss: 3.2035 - val_acc: 0.7432\n",
      "Epoch 79/100\n",
      " - 5s - loss: 0.0013 - acc: 0.9997 - val_loss: 3.1516 - val_acc: 0.7535\n",
      "Epoch 80/100\n",
      " - 6s - loss: 0.0027 - acc: 0.9994 - val_loss: 3.0672 - val_acc: 0.7554\n",
      "Epoch 81/100\n",
      " - 6s - loss: 0.0016 - acc: 0.9997 - val_loss: 3.0327 - val_acc: 0.7582\n",
      "Epoch 82/100\n",
      " - 6s - loss: 0.0022 - acc: 0.9998 - val_loss: 3.1434 - val_acc: 0.7488\n",
      "Epoch 83/100\n",
      " - 6s - loss: 0.0017 - acc: 0.9997 - val_loss: 3.1533 - val_acc: 0.7479\n",
      "Epoch 84/100\n",
      " - 6s - loss: 2.7737e-04 - acc: 0.9999 - val_loss: 3.1780 - val_acc: 0.7479\n",
      "Epoch 85/100\n",
      " - 6s - loss: 0.0012 - acc: 0.9996 - val_loss: 3.1558 - val_acc: 0.7516\n",
      "Epoch 86/100\n",
      " - 6s - loss: 0.0033 - acc: 0.9992 - val_loss: 3.1169 - val_acc: 0.7488\n",
      "Epoch 87/100\n",
      " - 6s - loss: 0.0055 - acc: 0.9993 - val_loss: 3.1085 - val_acc: 0.7545\n",
      "Epoch 88/100\n",
      " - 6s - loss: 8.7190e-04 - acc: 0.9996 - val_loss: 3.1226 - val_acc: 0.7516\n",
      "Epoch 89/100\n",
      " - 5s - loss: 0.0024 - acc: 0.9994 - val_loss: 3.2225 - val_acc: 0.7507\n",
      "Epoch 90/100\n",
      " - 5s - loss: 0.0037 - acc: 0.9995 - val_loss: 3.2050 - val_acc: 0.7545\n",
      "Epoch 91/100\n",
      " - 6s - loss: 0.0018 - acc: 0.9997 - val_loss: 3.1726 - val_acc: 0.7470\n",
      "Epoch 92/100\n",
      " - 5s - loss: 0.0035 - acc: 0.9996 - val_loss: 3.2700 - val_acc: 0.7470\n",
      "Epoch 93/100\n",
      " - 6s - loss: 0.0019 - acc: 0.9993 - val_loss: 3.2539 - val_acc: 0.7479\n",
      "Epoch 94/100\n",
      " - 6s - loss: 9.8492e-04 - acc: 0.9997 - val_loss: 3.2950 - val_acc: 0.7432\n",
      "Epoch 95/100\n",
      " - 6s - loss: 0.0020 - acc: 0.9997 - val_loss: 3.2220 - val_acc: 0.7470\n",
      "Epoch 96/100\n",
      " - 6s - loss: 0.0038 - acc: 0.9994 - val_loss: 3.2972 - val_acc: 0.7451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      " - 6s - loss: 1.5686e-05 - acc: 1.0000 - val_loss: 3.1914 - val_acc: 0.7526\n",
      "Epoch 98/100\n",
      " - 6s - loss: 0.0015 - acc: 0.9998 - val_loss: 3.1834 - val_acc: 0.7507\n",
      "Epoch 99/100\n",
      " - 6s - loss: 0.0025 - acc: 0.9995 - val_loss: 3.2276 - val_acc: 0.7498\n",
      "Epoch 100/100\n",
      " - 6s - loss: 8.2668e-05 - acc: 1.0000 - val_loss: 3.1403 - val_acc: 0.7582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1eca36e5c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training model\n",
    "# ==================================================\n",
    "model.fit(x_shuffled, y_shuffled, batch_size=batch_size,\n",
    "          nb_epoch=num_epochs, validation_split=val_split, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Another Example\n",
    "\n",
    "Using Keras + [**GloVe**](http://nlp.stanford.edu/projects/glove/) - **Global Vectors for Word Representation**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
