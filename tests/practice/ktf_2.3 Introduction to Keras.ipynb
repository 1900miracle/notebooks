{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/keras-logo-small.jpg\" width=\"20%\" />\n",
    "\n",
    "## Keras: Deep Learning library for Theano and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Keras is a minimalist, highly modular neural networks library, written in Python and capable of running on top of either TensorFlow or Theano. \n",
    "\n",
    ">It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
    "ref: https://keras.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"kaggle\"></a>\n",
    "### Kaggle Challenge Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The Otto Group is one of the worldâ€™s biggest e-commerce companies, A consistent analysis of the performance of products is crucial. However, due to diverse global infrastructure, many identical products get classified differently.\n",
    "For this competition, we have provided a dataset with 93 features for more than 200,000 products. The objective is to build a predictive model which is able to distinguish between our main product categories. \n",
    "Each row corresponds to a single product. There are a total of 93 numerical features, which represent counts of different events. All features have been obfuscated and will not be defined any further.\n",
    "\n",
    "https://www.kaggle.com/c/otto-group-product-classification-challenge/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For this section we will use the Kaggle Otto Group Challenge Data. You will find these data in \n",
    "`../data/kaggle_ottogroup/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "Using TensorFlow backend.\n",
      "/srv/venv/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gopala KR \n",
      "last updated: 2018-02-18 \n",
      "\n",
      "CPython 3.5.3\n",
      "IPython 6.2.1\n",
      "\n",
      "watermark 1.6.0\n",
      "numpy 1.13.3\n",
      "pandas 0.22.0\n",
      "matplotlib 2.1.2\n",
      "nltk 3.2.5\n",
      "sklearn 0.19.1\n",
      "tensorflow 1.5.0\n",
      "theano 1.0.1\n",
      "mxnet 1.0.0\n",
      "chainer 3.3.0\n",
      "seaborn 0.8.1\n",
      "keras 2.1.4\n",
      "tflearn n\u0007\n",
      "bokeh 0.12.14\n",
      "gensim 3.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.5/site-packages/scipy/sparse/sparsetools.py:20: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "#load watermark\n",
    "%load_ext watermark\n",
    "%watermark -a 'Gopala KR' -u -d -v -p watermark,numpy,pandas,matplotlib,nltk,sklearn,tensorflow,theano,mxnet,chainer,seaborn,keras,tflearn,bokeh,gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_data import load_data, preprocess_data, preprocess_labels\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 classes\n",
      "93 dims\n"
     ]
    }
   ],
   "source": [
    "X_train, labels = load_data('../data/kaggle_ottogroup/train.csv', train=True)\n",
    "X_train, scaler = preprocess_data(X_train)\n",
    "Y_train, encoder = preprocess_labels(labels)\n",
    "\n",
    "X_test, ids = load_data('../data/kaggle_ottogroup/test.csv', train=False)\n",
    "X_test, _ = preprocess_data(X_test, scaler)\n",
    "\n",
    "nb_classes = Y_train.shape[1]\n",
    "print(nb_classes, 'classes')\n",
    "\n",
    "dims = X_train.shape[1]\n",
    "print(dims, 'dims')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6',\n",
       "       'Class_7', 'Class_8', 'Class_9'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train  # one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano as th\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "target values for Data:\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "prediction on training set:\n",
      "[False False False ...,  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "#Based on example from DeepLearning.net\n",
    "rng = np.random\n",
    "N = 400\n",
    "feats = 93\n",
    "training_steps = 10\n",
    "\n",
    "# Declare Theano symbolic variables\n",
    "x = T.matrix(\"x\")\n",
    "y = T.vector(\"y\")\n",
    "w = th.shared(rng.randn(feats), name=\"w\")\n",
    "b = th.shared(0., name=\"b\")\n",
    "\n",
    "# Construct Theano expression graph\n",
    "p_1 = 1 / (1 + T.exp(-T.dot(x, w) - b))         # Probability that target = 1\n",
    "prediction = p_1 > 0.5                          # The prediction thresholded\n",
    "xent = -y * T.log(p_1) - (1-y) * T.log(1-p_1)   # Cross-entropy loss function\n",
    "cost = xent.mean() + 0.01 * (w ** 2).sum()      # The cost to minimize\n",
    "gw, gb = T.grad(cost, [w, b])                   # Compute the gradient of the cost\n",
    "                                                \n",
    "\n",
    "# Compile\n",
    "train = th.function(\n",
    "          inputs=[x,y],\n",
    "          outputs=[prediction, xent],\n",
    "          updates=((w, w - 0.1 * gw), (b, b - 0.1 * gb)),\n",
    "          allow_input_downcast=True)\n",
    "predict = th.function(inputs=[x], outputs=prediction, allow_input_downcast=True)\n",
    "\n",
    "#Transform for class1\n",
    "y_class1 = []\n",
    "for i in Y_train:\n",
    "    y_class1.append(i[0])\n",
    "y_class1 = np.array(y_class1)\n",
    "\n",
    "# Train\n",
    "for i in range(training_steps):\n",
    "    print('Epoch %s' % (i+1,))\n",
    "    pred, err = train(X_train, y_class1)\n",
    "\n",
    "print(\"target values for Data:\")\n",
    "print(y_class1)\n",
    "print(\"prediction on training set:\")\n",
    "print(predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 25\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph Input\n",
    "x = tf.placeholder(\"float\", [None, dims]) \n",
    "y = tf.placeholder(\"float\", [None, nb_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder:0' shape=(?, 93) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model (Introducing Tensorboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    }
   ],
   "source": [
    "# Construct (linear) model\n",
    "with tf.name_scope(\"model\") as scope:\n",
    "    # Set model weights\n",
    "    W = tf.Variable(tf.zeros([dims, nb_classes]))\n",
    "    b = tf.Variable(tf.zeros([nb_classes]))\n",
    "    activation = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "\n",
    "    # Add summary ops to collect data\n",
    "    w_h = tf.summary.histogram(\"weights_histogram\", W)\n",
    "    b_h = tf.summary.histogram(\"biases_histograms\", b)\n",
    "    tf.summary.scalar('mean_weights', tf.reduce_mean(W))\n",
    "    tf.summary.scalar('mean_bias', tf.reduce_mean(b))\n",
    "\n",
    "# Minimize error using cross entropy\n",
    "# Note: More name scopes will clean up graph representation\n",
    "with tf.name_scope(\"cost_function\") as scope:\n",
    "    cross_entropy = y*tf.log(activation)\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(cross_entropy,reduction_indices=1))\n",
    "    # Create a summary to monitor the cost function\n",
    "    tf.summary.scalar(\"cost_function\", cost)\n",
    "    tf.summary.histogram(\"cost_histogram\", cost)\n",
    "\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    # Set the Optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('Accuracy') as scope:\n",
    "    correct_prediction = tf.equal(tf.argmax(activation, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    # Create a summary to monitor the cost function\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning in a TF Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = \"/tmp/logistic_logs\"\n",
    "import os, shutil\n",
    "if os.path.isdir(LOGDIR):\n",
    "    shutil.rmtree(LOGDIR)\n",
    "os.mkdir(LOGDIR)\n",
    "\n",
    "# Plug TensorBoard Visualisation \n",
    "writer = tf.summary.FileWriter(LOGDIR, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/weights_histogram:0\n",
      "model/biases_histograms:0\n",
      "model/mean_weights:0\n",
      "model/mean_bias:0\n",
      "cost_function/cost_function:0\n",
      "cost_function/cost_histogram:0\n",
      "Accuracy/accuracy:0\n",
      "Tensor(\"add:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for var in tf.get_collection(tf.GraphKeys.SUMMARIES):\n",
    "    print(var.name)\n",
    "    \n",
    "summary_op = tf.summary.merge_all()\n",
    "print('Summary Op: ' + summary_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy epoch 0:0.6649535894393921\n",
      "accuracy epoch 1:0.665276825428009\n",
      "accuracy epoch 2:0.6657131910324097\n",
      "accuracy epoch 3:0.6659556031227112\n",
      "accuracy epoch 4:0.6662949919700623\n",
      "accuracy epoch 5:0.6666020154953003\n",
      "accuracy epoch 6:0.6668121218681335\n",
      "accuracy epoch 7:0.6671029925346375\n",
      "accuracy epoch 8:0.6674585342407227\n",
      "accuracy epoch 9:0.6678463816642761\n",
      "accuracy epoch 10:0.6680887937545776\n",
      "accuracy epoch 11:0.6682342886924744\n",
      "accuracy epoch 12:0.6684605479240417\n",
      "accuracy epoch 13:0.6687514185905457\n",
      "accuracy epoch 14:0.6690422892570496\n",
      "accuracy epoch 15:0.6692523956298828\n",
      "accuracy epoch 16:0.6695109605789185\n",
      "accuracy epoch 17:0.6697856783866882\n",
      "accuracy epoch 18:0.6699796319007874\n",
      "accuracy epoch 19:0.6702058911323547\n",
      "accuracy epoch 20:0.6705452799797058\n",
      "accuracy epoch 21:0.6708361506462097\n",
      "accuracy epoch 22:0.6710785627365112\n",
      "accuracy epoch 23:0.671385645866394\n",
      "accuracy epoch 24:0.6716926693916321\n",
      "Training phase finished\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUcIQEZFQlDBERCSU/w9WBfYTqxGICQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4f32d11828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5 5 ..., 2 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as session:\n",
    "    # Initializing the variables\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    cost_epochs = []\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        _, summary, c = session.run(fetches=[optimizer, summary_op, cost], \n",
    "                                    feed_dict={x: X_train, y: Y_train})\n",
    "        cost_epochs.append(c)\n",
    "        writer.add_summary(summary=summary, global_step=epoch)\n",
    "        print(\"accuracy epoch {}:{}\".format(epoch, accuracy.eval({x: X_train, y: Y_train})))\n",
    "        \n",
    "    print(\"Training phase finished\")\n",
    "    \n",
    "    #plotting\n",
    "    plt.plot(range(len(cost_epochs)), cost_epochs, 'o', label='Logistic Regression Training phase')\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    prediction = tf.argmax(activation, 1)\n",
    "    print(prediction.eval({x: X_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/bin/python: No module named tensorflow.tensorboard\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -m tensorflow.tensorboard --logdir=/tmp/logistic_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 dims\n",
      "Building model...\n",
      "9 classes\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61878/61878 [==============================] - 4s 60us/step - loss: 1.9954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f31999358>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims = X_train.shape[1]\n",
    "print(dims, 'dims')\n",
    "print(\"Building model...\")\n",
    "\n",
    "nb_classes = Y_train.shape[1]\n",
    "print(nb_classes, 'classes')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(nb_classes, input_shape=(dims,), activation='sigmoid'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplicity is pretty impressive right? :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theano**:\n",
    "\n",
    "`shape = (channels, rows, cols)`\n",
    "\n",
    "**Tensorflow**:\n",
    "\n",
    "`shape = (rows, cols, channels)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`image_data_format` : `channels_last | channels_first`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"epsilon\": 1e-07,\r\n",
      "    \"backend\": \"tensorflow\",\r\n",
      "    \"image_data_format\": \"channels_last\",\r\n",
      "    \"floatx\": \"float32\"\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat ~/.keras/keras.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets understand:\n",
    "<pre>The core data structure of Keras is a <b>model</b>, a way to organize layers. The main type of model is the <b>Sequential</b> model, a linear stack of layers.</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did here is stacking a Fully Connected (<b>Dense</b>) layer of trainable weights from the input to the output and an <b>Activation</b> layer on top of the weights layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "Dense(units, activation=None, use_bias=True, \n",
    "      kernel_initializer='glorot_uniform', bias_initializer='zeros', \n",
    "      kernel_regularizer=None, bias_regularizer=None, \n",
    "      activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `units`: int > 0.\n",
    "\n",
    "* `init`: name of initialization function for the weights of the layer (see initializations), or alternatively, Theano function to use for weights initialization. This parameter is only relevant if you don't pass a weights argument.\n",
    "\n",
    "* `activation`: name of activation function to use (see activations), or alternatively, elementwise Theano function. If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "\n",
    "* `weights`: list of Numpy arrays to set as initial weights. The list should have 2 elements, of shape (input_dim, output_dim) and (output_dim,) for weights and biases respectively.\n",
    "\n",
    "* `kernel_regularizer`: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the main weights matrix.\n",
    "\n",
    "* `bias_regularizer`: instance of WeightRegularizer, applied to the bias.\n",
    "\n",
    "* `activity_regularizer`: instance of ActivityRegularizer, applied to the network output.\n",
    "\n",
    "* `kernel_constraint`: instance of the constraints module (eg. maxnorm, nonneg), applied to the main weights matrix.\n",
    "\n",
    "* `bias_constraint`: instance of the constraints module, applied to the bias.\n",
    "\n",
    "* `use_bias`: whether to include a bias (i.e. make the layer affine rather than linear)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (some) others `keras.core.layers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `keras.layers.core.Flatten()`\n",
    "* `keras.layers.core.Reshape(target_shape)`\n",
    "* `keras.layers.core.Permute(dims)`\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Permute((2, 1), input_shape=(10, 64)))\n",
    "# now: model.output_shape == (None, 64, 10)\n",
    "# note: `None` is the batch dimension\n",
    "```\n",
    "\n",
    "* `keras.layers.core.Lambda(function, output_shape=None, arguments=None)`\n",
    "* `keras.layers.core.ActivityRegularization(l1=0.0, l2=0.0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/dl_overview.png\" >\n",
    "\n",
    "Credits: Yam Peleg ([@Yampeleg](https://twitter.com/yampeleg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "from keras.layers.core import Activation\n",
    "\n",
    "Activation(activation)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Supported Activations** : [https://keras.io/activations/]\n",
    "\n",
    "**Advanced Activations**: [https://keras.io/layers/advanced-activations/]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to, you can further configure your optimizer. A core principle of Keras is to make things reasonably simple, while allowing the user to be fully in control when they need to (the ultimate control being the easy extensibility of the source code).\n",
    "Here we used <b>SGD</b> (stochastic gradient descent) as an optimization algorithm for our trainable weights.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://sebastianruder.com/content/images/2016/09/saddle_point_evaluation_optimizers.gif\" width=\"40%\">\n",
    "\n",
    "Source & Reference: http://sebastianruder.com/content/images/2016/09/saddle_point_evaluation_optimizers.gif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Data Sciencing\" this example a little bit more\n",
    "====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did here is nice, however in the real world it is not useable because of overfitting.\n",
    "Lets try and solve it with cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In overfitting, a statistical model describes random error or noise instead of the underlying relationship. Overfitting occurs when a model is excessively complex, such as having too many parameters relative to the number of observations. \n",
    "\n",
    "A model that has been overfit has poor predictive performance, as it overreacts to minor fluctuations in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"../imgs/overfitting.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>To avoid overfitting, we will first split out data to training set and test set and test out model on the test set.\n",
    "Next: we will use two of keras's callbacks <b>EarlyStopping</b> and <b>ModelCheckpoint</b></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see first the model we implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 9)                 846       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 846\n",
      "Trainable params: 846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52596 samples, validate on 9282 samples\n",
      "Epoch 1/5\n",
      "52596/52596 [==============================] - 1s 17us/step - loss: 1.8757 - val_loss: 1.8600\n",
      "Epoch 2/5\n",
      "52596/52596 [==============================] - 1s 16us/step - loss: 1.8551 - val_loss: 1.8412\n",
      "Epoch 3/5\n",
      "52596/52596 [==============================] - 1s 16us/step - loss: 1.8379 - val_loss: 1.8254\n",
      "Epoch 4/5\n",
      "52596/52596 [==============================] - 1s 17us/step - loss: 1.8233 - val_loss: 1.8117\n",
      "Epoch 5/5\n",
      "52596/52596 [==============================] - 1s 15us/step - loss: 1.8105 - val_loss: 1.7998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f343c4588>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.15, random_state=42)\n",
    "\n",
    "fBestModel = 'best_model.h5' \n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, verbose=1) \n",
    "best_model = ModelCheckpoint(fBestModel, verbose=0, save_best_only=True)\n",
    "\n",
    "model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs=5, \n",
    "          batch_size=128, verbose=True, callbacks=[best_model, early_stop]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Fully Connected Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/MLP.png\" width=\"45%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward and Backward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/backprop.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** _How hard can it be to build a Multi-Layer Fully-Connected Network with keras?_\n",
    "\n",
    "**A:** _It is basically the same, just add more layers!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 100)               9400      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 909       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 10,309\n",
      "Trainable params: 10,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(dims,)))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52596 samples, validate on 9282 samples\n",
      "Epoch 1/5\n",
      "52596/52596 [==============================] - 2s 29us/step - loss: 1.1769 - val_loss: 0.8540\n",
      "Epoch 2/5\n",
      "52596/52596 [==============================] - 1s 22us/step - loss: 0.8228 - val_loss: 0.7681\n",
      "Epoch 3/5\n",
      "52596/52596 [==============================] - 1s 23us/step - loss: 0.7641 - val_loss: 0.7327\n",
      "Epoch 4/5\n",
      "52596/52596 [==============================] - 1s 25us/step - loss: 0.7344 - val_loss: 0.7126\n",
      "Epoch 5/5\n",
      "52596/52596 [==============================] - 1s 26us/step - loss: 0.7158 - val_loss: 0.6986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f33367400>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs=5, \n",
    "          batch_size=128, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands On - Keras Fully Connected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take couple of minutes and try to play with the number of layers and the number of parameters in the layers to get the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 100)               9400      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 9)                 909       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 10,309\n",
      "Trainable params: 10,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(dims,)))\n",
    "\n",
    "# ...\n",
    "# ...\n",
    "# Play with it! add as much layers as you want! try and get better results.\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52596 samples, validate on 9282 samples\n",
      "Epoch 1/5\n",
      "52596/52596 [==============================] - 2s 30us/step - loss: 0.8271 - val_loss: 0.6785\n",
      "Epoch 2/5\n",
      "52596/52596 [==============================] - 1s 24us/step - loss: 0.6746 - val_loss: 0.6541\n",
      "Epoch 3/5\n",
      "52596/52596 [==============================] - 1s 26us/step - loss: 0.6605 - val_loss: 0.6422\n",
      "Epoch 4/5\n",
      "52596/52596 [==============================] - 1s 27us/step - loss: 0.6549 - val_loss: 0.6430\n",
      "Epoch 5/5\n",
      "52596/52596 [==============================] - 1s 27us/step - loss: 0.6508 - val_loss: 0.6386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f2dd9d4e0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs=5, \n",
    "          batch_size=128, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a question answering system, an image classification model, a Neural Turing Machine, a word2vec embedder or any other model is just as fast. The ideas behind deep learning are simple, so why should their implementation be painful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theoretical Motivations for depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Much has been studied about the depth of neural nets. Is has been proven mathematically[1] and empirically that convolutional neural network benifit from depth! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] - On the Expressive Power of Deep Learning: A Tensor Analysis - Cohen, et al 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theoretical Motivations for depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One much quoted theorem about neural network states that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Universal approximation theorem states[1] that a feed-forward network with a single hidden layer containing a finite number of neurons (i.e., a multilayer perceptron), can approximate continuous functions on compact subsets of $\\mathbb{R}^n$, under mild assumptions on the activation function. The theorem thus states that simple neural networks can represent a wide variety of interesting functions when given appropriate parameters; however, it does not touch upon the algorithmic learnability of those parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] - Approximation Capabilities of Multilayer Feedforward Networks - Kurt Hornik 1991"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addendum\n",
    "\n",
    "[2.3.1 Keras Backend](2.3.1  Keras Backend.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
