{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `keras.wrappers.scikit_learn`\n",
    "\n",
    "Example adapted from: [https://github.com/fchollet/keras/blob/master/examples/mnist_sklearn_wrapper.py]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: \n",
    "Builds simple CNN models on MNIST and uses sklearn's GridSearchCV to find best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "Using TensorFlow backend.\n",
      "/srv/venv/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gopala KR \n",
      "last updated: 2018-02-18 \n",
      "\n",
      "CPython 3.5.3\n",
      "IPython 6.2.1\n",
      "\n",
      "watermark 1.6.0\n",
      "numpy 1.13.3\n",
      "pandas 0.22.0\n",
      "matplotlib 2.1.2\n",
      "nltk 3.2.5\n",
      "sklearn 0.19.1\n",
      "tensorflow 1.5.0\n",
      "theano 1.0.1\n",
      "mxnet 1.0.0\n",
      "chainer 3.3.0\n",
      "seaborn 0.8.1\n",
      "keras 2.1.4\n",
      "tflearn n\u0007\n",
      "bokeh 0.12.14\n",
      "gensim 3.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.5/site-packages/scipy/sparse/sparsetools.py:20: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "#load watermark\n",
    "%load_ext watermark\n",
    "%watermark -a 'Gopala KR' -u -d -v -p watermark,numpy,pandas,matplotlib,nltk,sklearn,tensorflow,theano,mxnet,chainer,seaborn,keras,tflearn,bokeh,gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data and do basic data normalization\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(dense_layer_sizes, filters, kernel_size, pool_size):\n",
    "    '''Creates model comprised of 2 convolutional layers followed by dense layers\n",
    "\n",
    "    dense_layer_sizes: List of layer sizes. This list has one number for each layer\n",
    "    nb_filters: Number of convolutional filters in each convolutional layer\n",
    "    nb_conv: Convolutional kernel size\n",
    "    nb_pool: Size of pooling area for max pooling\n",
    "    '''\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters, (kernel_size, kernel_size),\n",
    "                     padding='valid', input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(filters, (kernel_size, kernel_size)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    for layer_size in dense_layer_sizes:\n",
    "        model.add(Dense(layer_size))\n",
    "        model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_size_candidates = [[32], [64], [32, 32], [64, 64]]\n",
    "my_classifier = KerasClassifier(make_model, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.5/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 20s 490us/step - loss: 0.6229 - acc: 0.7956\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 20s 491us/step - loss: 0.3636 - acc: 0.8853\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 19s 487us/step - loss: 0.3035 - acc: 0.9052\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 20s 489us/step - loss: 0.6423 - acc: 0.7869\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 20s 502us/step - loss: 0.3615 - acc: 0.88481s\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 20s 494us/step - loss: 0.3060 - acc: 0.9033\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 20s 502us/step - loss: 0.6081 - acc: 0.8013\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 20s 495us/step - loss: 0.3542 - acc: 0.8891\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 19s 481us/step - loss: 0.2954 - acc: 0.9080\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 20s 495us/step - loss: 0.6938 - acc: 0.7668\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 20s 496us/step - loss: 0.3934 - acc: 0.8754\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 19s 482us/step - loss: 0.3284 - acc: 0.8966\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 20s 498us/step - loss: 0.2903 - acc: 0.9110\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 20s 491us/step - loss: 0.2669 - acc: 0.9193\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 20s 488us/step - loss: 0.2486 - acc: 0.9254\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 21s 523us/step - loss: 0.6626 - acc: 0.7823\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 19s 487us/step - loss: 0.3860 - acc: 0.8789\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 19s 476us/step - loss: 0.3257 - acc: 0.8991\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 19s 475us/step - loss: 0.2912 - acc: 0.9110\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 20s 511us/step - loss: 0.2657 - acc: 0.9181\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 22s 547us/step - loss: 0.2530 - acc: 0.9233\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 22s 558us/step - loss: 0.5936 - acc: 0.8094\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 22s 539us/step - loss: 0.3447 - acc: 0.8935\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 22s 544us/step - loss: 0.2932 - acc: 0.9096\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 21s 527us/step - loss: 0.2628 - acc: 0.9179\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 21s 527us/step - loss: 0.2448 - acc: 0.9255\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 20s 503us/step - loss: 0.2366 - acc: 0.9299\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 19s 471us/step - loss: 0.5234 - acc: 0.8356\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 19s 481us/step - loss: 0.2546 - acc: 0.9250\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 19s 486us/step - loss: 0.1895 - acc: 0.9438\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 20s 491us/step - loss: 0.4324 - acc: 0.8666\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 19s 480us/step - loss: 0.2196 - acc: 0.9349\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 19s 481us/step - loss: 0.1793 - acc: 0.9474\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 20s 491us/step - loss: 0.4432 - acc: 0.8618\n",
      "Epoch 2/3\n",
      " 6400/40000 [===>..........................] - ETA: 26s - loss: 0.2350 - acc: 0.9320"
     ]
    }
   ],
   "source": [
    "validator = GridSearchCV(my_classifier,\n",
    "                         param_grid={'dense_layer_sizes': dense_size_candidates,\n",
    "                                     # nb_epoch is avail for tuning even when not\n",
    "                                     # an argument to model building function\n",
    "                                     'epochs': [3, 6],\n",
    "                                     'filters': [8],\n",
    "                                     'kernel_size': [3],\n",
    "                                     'pool_size': [2]},\n",
    "                         scoring='neg_log_loss',\n",
    "                         n_jobs=1)\n",
    "validator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The parameters of the best model are: ')\n",
    "print(validator.best_params_)\n",
    "\n",
    "# validator.best_estimator_ returns sklearn-wrapped version of best model.\n",
    "# validator.best_estimator_.model returns the (unwrapped) keras model\n",
    "best_model = validator.best_estimator_.model\n",
    "metric_names = best_model.metrics_names\n",
    "metric_values = best_model.evaluate(X_test, y_test)\n",
    "for metric, value in zip(metric_names, metric_values):\n",
    "    print(metric, ': ', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There's more:\n",
    "\n",
    "The `GridSearchCV` model in scikit-learn performs a complete search, considering **all** the possible combinations of Hyper-parameters we want to optimise.\n",
    "\n",
    "If we want to apply for an optmised and bounded search in the hyper-parameter space, I strongly suggest to take a look at:\n",
    "\n",
    "* `Keras + hyperopt == hyperas`: [http://maxpumperla.github.io/hyperas/](http://maxpumperla.github.io/hyperas/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
