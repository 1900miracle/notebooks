{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*Accompanying code examples of the book \"Introduction to Artificial Neural Networks and Deep Learning: A Practical Guide with Applications in Python\" by [Sebastian Raschka](https://sebastianraschka.com). All code examples are released under the [MIT license](https://github.com/rasbt/deep-learning-book/blob/master/LICENSE). If you find this content useful, please consider supporting the work by buying a [copy of the book](https://leanpub.com/ann-and-deeplearning).*\n",
    "  \n",
    "Other code examples and content are available on [GitHub](https://github.com/rasbt/deep-learning-book). The PDF and ebook versions of the book are available through [Leanpub](https://leanpub.com/ann-and-deeplearning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "Using TensorFlow backend.\n",
      "/srv/venv/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gopala KR \n",
      "last updated: 2018-02-28 \n",
      "\n",
      "CPython 3.6.3\n",
      "IPython 6.2.1\n",
      "\n",
      "watermark 1.6.0\n",
      "numpy 1.14.1\n",
      "matplotlib 2.1.2\n",
      "nltk 3.2.5\n",
      "sklearn 0.19.1\n",
      "tensorflow 1.5.0\n",
      "theano 1.0.1\n",
      "mxnet 1.1.0\n",
      "chainer 3.4.0\n",
      "seaborn 0.8.1\n",
      "keras 2.1.4\n",
      "tflearn n\u0007\n",
      "bokeh 0.12.14\n",
      "gensim 3.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.6/site-packages/scipy/sparse/sparsetools.py:20: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "#load watermark\n",
    "%load_ext watermark\n",
    "%watermark -a 'Gopala KR' -u -d -v -p watermark,numpy,matplotlib,nltk,sklearn,tensorflow,theano,mxnet,chainer,seaborn,keras,tflearn,bokeh,gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Zoo -- Convolutional Autoencoder with Deconvolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A convolutional autoencoder using deconvolutional layers that compresses 768-pixel MNIST images down to a 7x7x4 (196 pixel) representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/venv/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py:539: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\n",
      "/srv/venv/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "##########################\n",
    "### DATASET\n",
    "##########################\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./\", validation_size=0)\n",
    "\n",
    "\n",
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "# Architecture\n",
    "hidden_size = 16\n",
    "input_size = 784\n",
    "image_width = 28\n",
    "\n",
    "# Other\n",
    "print_interval = 200\n",
    "random_seed = 123\n",
    "\n",
    "\n",
    "##########################\n",
    "### GRAPH DEFINITION\n",
    "##########################\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    \n",
    "    tf.set_random_seed(random_seed)\n",
    "\n",
    "    # Input data\n",
    "    tf_x = tf.placeholder(tf.float32, [None, input_size], name='inputs')\n",
    "    input_layer = tf.reshape(tf_x, shape=[-1, image_width, image_width, 1])\n",
    "\n",
    "    ###########\n",
    "    # Encoder\n",
    "    ###########\n",
    "    \n",
    "    # 28x28x1 => 28x28x8\n",
    "    conv1 = tf.layers.conv2d(input_layer, filters=8, kernel_size=(3, 3),\n",
    "                             strides=(1, 1), padding='same', \n",
    "                             activation=tf.nn.relu)\n",
    "    # 28x28x8 => 14x14x8\n",
    "    maxpool1 = tf.layers.max_pooling2d(conv1, pool_size=(2, 2), \n",
    "                                       strides=(2, 2), padding='same')\n",
    "    \n",
    "    # 14x14x8 => 14x14x4\n",
    "    conv2 = tf.layers.conv2d(maxpool1, filters=4, kernel_size=(3, 3), \n",
    "                             strides=(1, 1), padding='same', \n",
    "                             activation=tf.nn.relu)\n",
    "    \n",
    "    # 14x14x4 => 7x7x4\n",
    "    encode = tf.layers.max_pooling2d(conv2, pool_size=(2, 2), \n",
    "                                     strides=(2, 2), padding='same', \n",
    "                                     name='encoding')\n",
    "\n",
    "    ###########\n",
    "    # Decoder\n",
    "    ###########\n",
    "    \n",
    "    # 7x7x4 => 14x14x8\n",
    "    deconv1 = tf.layers.conv2d_transpose(encode, filters=8, \n",
    "                                         kernel_size=(3, 3), strides=(2, 2), \n",
    "                                         padding='same',\n",
    "                                         activation=tf.nn.relu)\n",
    "    \n",
    "    \n",
    "    # 14x14x8 => 28x28x8\n",
    "    deconv2 = tf.layers.conv2d_transpose(deconv1, filters=8, \n",
    "                                         kernel_size=(3, 3), strides=(2, 2), \n",
    "                                         padding='same',\n",
    "                                         activation=tf.nn.relu)\n",
    "    \n",
    "    # 28x28x8 => 28x28x1\n",
    "    logits = tf.layers.conv2d(deconv2, filters=1, kernel_size=(3,3), \n",
    "                              strides=(1, 1), padding='same', \n",
    "                              activation=None)\n",
    "    \n",
    "    decode = tf.nn.sigmoid(logits, name='decoding')\n",
    "\n",
    "    ##################\n",
    "    # Loss & Optimizer\n",
    "    ##################\n",
    "    \n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=input_layer,\n",
    "                                                   logits=logits)\n",
    "    cost = tf.reduce_mean(loss, name='cost')\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train = optimizer.minimize(cost, name='train')    \n",
    "\n",
    "    # Saver to save session for reuse\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch: 001 | Cost:    0.692\n",
      "Minibatch: 201 | Cost:    0.174\n",
      "Minibatch: 401 | Cost:    0.111\n",
      "Epoch:     001 | AvgCost: 0.225\n",
      "Minibatch: 001 | Cost:    0.105\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "##########################\n",
    "### TRAINING & EVALUATION\n",
    "##########################\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    np.random.seed(random_seed) # random seed for mnist iterator\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            _, c = sess.run(['train', 'cost:0'], feed_dict={'inputs:0': batch_x})\n",
    "\n",
    "            avg_cost += c\n",
    "\n",
    "            if not i % print_interval:\n",
    "                print(\"Minibatch: %03d | Cost:    %.3f\" % (i + 1, c))\n",
    "\n",
    "        print(\"Epoch:     %03d | AvgCost: %.3f\" % (epoch + 1, avg_cost / (i + 1)))\n",
    "    \n",
    "    saver.save(sess, save_path='./autoencoder.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##########################\n",
    "### VISUALIZATION\n",
    "##########################\n",
    "\n",
    "n_images = 15\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=n_images, sharex=True, \n",
    "                         sharey=True, figsize=(20, 2.5))\n",
    "test_images = mnist.test.images[:n_images]\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    saver.restore(sess, save_path='./autoencoder.ckpt')\n",
    "    decoded = sess.run('decoding:0', feed_dict={'inputs:0': test_images})\n",
    "\n",
    "for i in range(n_images):\n",
    "    for ax, img in zip(axes, [test_images, decoded]):\n",
    "        ax[i].imshow(img[i].reshape((image_width, image_width)), cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
