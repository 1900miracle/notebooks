{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMPLE CHAR-RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TENSORFLOW VERSION IS 1.3.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "tf.set_random_seed(0)  \n",
    "print (\"TENSORFLOW VERSION IS %s\" % (tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE TRAINING SEQUENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLLOWING IS OUR TRAINING SEQUENCE:\n",
      "Perfection is achieved, not when there is nothing more to add, but when there is nothing left to take away.\n"
     ]
    }
   ],
   "source": [
    "quote1 = (\"If you want to build a ship, \"\n",
    "          \"don't drum up people to collect wood and don't assign them tasks and work,\"\n",
    "          \" but rather teach them to long for the endless immensity of the sea.\")\n",
    "quote2 = (\"Perfection is achieved, \"\n",
    "          \"not when there is nothing more to add, \"\n",
    "          \"but when there is nothing left to take away.\")\n",
    "sentence = quote2\n",
    "print (\"FOLLOWING IS OUR TRAINING SEQUENCE:\")\n",
    "print (sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE VOCABULARY AND DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCABULARY: \n",
      "['c', 'g', 'l', 'w', 'k', 'n', 'y', 'v', 'u', 'b', 'm', '.', ' ', 'f', 't', 'd', 'e', 'i', ',', 'o', 's', 'r', 'h', 'P', 'a']\n",
      "DICTIONARY: \n",
      "{'c': 0, 'g': 1, 'l': 2, 'w': 3, 'k': 4, 'n': 5, 'y': 6, 'v': 7, 'u': 8, 'b': 9, 'm': 10, '.': 11, ' ': 12, 'f': 13, 't': 14, 'd': 15, 'e': 16, 'i': 17, ',': 18, 'o': 19, 's': 20, 'r': 21, 'h': 22, 'P': 23, 'a': 24}\n"
     ]
    }
   ],
   "source": [
    "char_set = list(set(sentence))\n",
    "char_dic = {w: i for i, w in enumerate(char_set)}\n",
    "print (\"VOCABULARY: \")\n",
    "print (char_set)\n",
    "print (\"DICTIONARY: \")\n",
    "print (char_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VOCAB: NUMBER => CHAR / DICTIONARY: CHAR => NUMBER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIGURE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIM IS [25]\n"
     ]
    }
   ],
   "source": [
    "data_dim        = len(char_set)\n",
    "num_classes     = len(char_set)\n",
    "hidden_size     = 64\n",
    "sequence_length = 10  # Any arbitrary number \n",
    "print (\"DATA_DIM IS [%d]\" % (data_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET TRAINING BATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_np(_name, _x):\n",
    "    print(\"TYPE  OF [%s] is [%s]\" % (_name, type(_x)))\n",
    "    print(\"SHAPE OF [%s] is %s\" % (_name, _x.shape,))\n",
    "def print_list(_name, _x):\n",
    "    print(\"TYPE   OF [%s] is [%s]\" % (_name, type(_x)))\n",
    "    print(\"LENGTH OF [%s] is %s\" % (_name, len(_x)))\n",
    "    print(\"%s[0] LOOKS LIKE %s\" % (_name, _x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0/ 107] [Perfection]=>[erfection ]\n",
      "            [23, 16, 21, 13, 16, 0, 14, 17, 19, 5] => [16, 21, 13, 16, 0, 14, 17, 19, 5, 12]\n",
      "[   1/ 107] [erfection ]=>[rfection i]\n",
      "            [16, 21, 13, 16, 0, 14, 17, 19, 5, 12] => [21, 13, 16, 0, 14, 17, 19, 5, 12, 17]\n",
      "[   2/ 107] [rfection i]=>[fection is]\n",
      "            [21, 13, 16, 0, 14, 17, 19, 5, 12, 17] => [13, 16, 0, 14, 17, 19, 5, 12, 17, 20]\n",
      "[   3/ 107] [fection is]=>[ection is ]\n",
      "            [13, 16, 0, 14, 17, 19, 5, 12, 17, 20] => [16, 0, 14, 17, 19, 5, 12, 17, 20, 12]\n",
      "[   4/ 107] [ection is ]=>[ction is a]\n",
      "            [16, 0, 14, 17, 19, 5, 12, 17, 20, 12] => [0, 14, 17, 19, 5, 12, 17, 20, 12, 24]\n",
      "TYPE   OF [dataX] is [<class 'list'>]\n",
      "LENGTH OF [dataX] is 97\n",
      "dataX[0] LOOKS LIKE [23, 16, 21, 13, 16, 0, 14, 17, 19, 5]\n",
      "TYPE   OF [dataY] is [<class 'list'>]\n",
      "LENGTH OF [dataY] is 97\n",
      "dataY[0] LOOKS LIKE [16, 21, 13, 16, 0, 14, 17, 19, 5, 12]\n"
     ]
    }
   ],
   "source": [
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(sentence) - sequence_length):\n",
    "    x_str = sentence[i:i + sequence_length]\n",
    "    y_str = sentence[i + 1: i + sequence_length + 1]\n",
    "    x = [char_dic[c] for c in x_str]  # x str to index\n",
    "    y = [char_dic[c] for c in y_str]  # y str to index\n",
    "    dataX.append(x)\n",
    "    dataY.append(y)\n",
    "    if i < 5:\n",
    "        print (\"[%4d/%4d] [%s]=>[%s]\" % (i, len(sentence), x_str, y_str))\n",
    "        print (\"%s%s => %s\" % (' '*12, x, y))\n",
    "print_list('dataX', dataX)\n",
    "print_list('dataY', dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     'NDATA' IS 97\n",
      "'BATCH_SIZE' IS 512\n"
     ]
    }
   ],
   "source": [
    "ndata      = len(dataX)\n",
    "batch_size = 512\n",
    "print (\"     'NDATA' IS %d\" % (ndata))\n",
    "print (\"'BATCH_SIZE' IS %d\" % (batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE PLACEHOLDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'sequence_length' IS [10]\n",
      "    'num_classes' IS [25]\n",
      "'X' LOOKS LIKE \n",
      "   [Tensor(\"Placeholder:0\", shape=(?, 10), dtype=int32)]\n",
      "'X_OH' LOOKS LIKE \n",
      "   [Tensor(\"one_hot:0\", shape=(?, 10, 25), dtype=float32)]\n",
      "'Y' LOOKS LIKE \n",
      "   [Tensor(\"Placeholder_1:0\", shape=(?, 10), dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "X_OH = tf.one_hot(X, num_classes)\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "print (\"'sequence_length' IS [%d]\" % (sequence_length))\n",
    "print (\"    'num_classes' IS [%d]\" % (num_classes))\n",
    "print(\"'X' LOOKS LIKE \\n   [%s]\" % (X))  \n",
    "print(\"'X_OH' LOOKS LIKE \\n   [%s]\" % (X_OH))\n",
    "print(\"'Y' LOOKS LIKE \\n   [%s]\" % (Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_hiddens   LOOKS LIKE [Tensor(\"CHAR-RNN/fully_connected/Relu:0\", shape=(?, 10, 64), dtype=float32)]\n",
      "_rnnouts   LOOKS LIKE [Tensor(\"CHAR-RNN/rnn/transpose:0\", shape=(?, 10, 64), dtype=float32)]\n",
      "_denseouts LOOKS LIKE [Tensor(\"CHAR-RNN/fully_connected_1/BiasAdd:0\", shape=(?, 10, 25), dtype=float32)]\n",
      "outputs    LOOKS LIKE [Tensor(\"CHAR-RNN/Reshape:0\", shape=(512, 10, 25), dtype=float32)]\n",
      "MODEL DEFINED.\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('CHAR-RNN', reuse=False):\n",
    "    cell = rnn.BasicLSTMCell(hidden_size, state_is_tuple=True, reuse=False)\n",
    "    # cell = rnn.MultiRNNCell([cell]*2, state_is_tuple=True) # BUG IN TF1.1..\n",
    "    # DYNAMIC RNN WITH FULLY CONNECTED LAYER\n",
    "    _hiddens  = tf.contrib.layers.fully_connected(X_OH, hidden_size, activation_fn=tf.nn.relu)\n",
    "    _rnnouts, _states = tf.nn.dynamic_rnn(cell, _hiddens, dtype=tf.float32)\n",
    "    _denseouts = tf.contrib.layers.fully_connected(_rnnouts, num_classes, activation_fn=None)\n",
    "    # RESHAPE FOR SEQUNCE LOSS\n",
    "    outputs = tf.reshape(_denseouts, [batch_size, sequence_length, num_classes])\n",
    "    \n",
    "print (\"_hiddens   LOOKS LIKE [%s]\" % (_hiddens))\n",
    "print (\"_rnnouts   LOOKS LIKE [%s]\" % (_rnnouts))\n",
    "print (\"_denseouts LOOKS LIKE [%s]\" % (_denseouts))\n",
    "print (\"outputs    LOOKS LIKE [%s]\" % (outputs))\n",
    "print (\"MODEL DEFINED.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE TF FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights LOOKS LIKE [Tensor(\"ones:0\", shape=(512, 10), dtype=float32)]\n",
      "outputs LOOKS LIKE [Tensor(\"CHAR-RNN/Reshape:0\", shape=(512, 10, 25), dtype=float32)]\n",
      "Y       LOOKS LIKE [Tensor(\"Placeholder_1:0\", shape=(?, 10), dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "weights  = tf.ones([batch_size, sequence_length]) # EQUAL WEIGHTS\n",
    "seq_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "    logits=outputs, targets=Y, weights=weights) # THIS IS A CLASSIFICATION LOSS\n",
    "print (\"weights LOOKS LIKE [%s]\" % (weights))\n",
    "print (\"outputs LOOKS LIKE [%s]\" % (outputs))\n",
    "print (\"Y       LOOKS LIKE [%s]\" % (Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTIONS DEFINED.\n"
     ]
    }
   ],
   "source": [
    "loss  = tf.reduce_mean(seq_loss)\n",
    "optm  = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)\n",
    "print (\"FUNCTIONS DEFINED.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIMIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0/2000] loss_val: 3.22481 \n",
      "[  200/2000] loss_val: 0.17731 \n",
      "[  400/2000] loss_val: 0.17315 \n",
      "[  600/2000] loss_val: 0.17406 \n",
      "[  800/2000] loss_val: 0.16724 \n",
      "[ 1000/2000] loss_val: 0.17626 \n",
      "[ 1200/2000] loss_val: 0.17269 \n",
      "[ 1400/2000] loss_val: 0.17289 \n",
      "[ 1600/2000] loss_val: 0.16823 \n",
      "[ 1800/2000] loss_val: 0.17249 \n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "MAXITER = 2000\n",
    "for i in range(MAXITER):\n",
    "    randidx = np.random.randint(low=0, high=ndata, size=batch_size)\n",
    "    batchX = [dataX[iii] for iii in randidx]\n",
    "    batchY = [dataY[iii] for iii in randidx]\n",
    "    feeds = {X: batchX, Y: batchY}\n",
    "    _, loss_val, results = sess.run(\n",
    "        [optm, loss, outputs], feed_dict=feeds)\n",
    "    if (i%200) == 0:\n",
    "        print (\"[%5d/%d] loss_val: %.5f \" % (i, MAXITER, loss_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BATCH LOOKS LIKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENGTH OF BATCHX IS 512\n",
      "batchX[0] looks like [17, 5, 1, 12, 10, 19, 21, 16, 12, 14]\n",
      "LENGTH OF BATCHY IS 512\n",
      "batchY[0] looks like [5, 1, 12, 10, 19, 21, 16, 12, 14, 19]\n"
     ]
    }
   ],
   "source": [
    "print (\"LENGTH OF BATCHX IS %d\" % (len(batchX)))\n",
    "print (\"batchX[0] looks like %s\" % (batchX[0]))\n",
    "print (\"LENGTH OF BATCHY IS %d\" % (len(batchY)))\n",
    "print (\"batchY[0] looks like %s\" % (batchY[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRINT CHARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUT OF BATCHX:   [20  1 12 10 16 13 14 12 14 19] => ['s', 'g', ' ', 'm', 'e', 'f', 't', ' ', 't', 'o']\n",
      "BATCHY (TARGET): [5, 1, 12, 2, 16, 13, 14, 12, 14, 19]\n",
      "\n",
      "OUT OF BATCHX:   [14 22 17  5  1 12 10 19 21 16] => ['t', 'h', 'i', 'n', 'g', ' ', 'm', 'o', 'r', 'e']\n",
      "BATCHY (TARGET): [14, 22, 17, 5, 1, 12, 10, 19, 21, 16]\n",
      "\n",
      "OUT OF BATCHX:   [22 16 21 16 12 17 20 12  5 19] => ['h', 'e', 'r', 'e', ' ', 'i', 's', ' ', 'n', 'o']\n",
      "BATCHY (TARGET): [22, 16, 21, 16, 12, 17, 20, 12, 5, 19]\n",
      "\n",
      "OUT OF BATCHX:   [14 17 19  5 12 17 20 12 24  0] => ['t', 'i', 'o', 'n', ' ', 'i', 's', ' ', 'a', 'c']\n",
      "BATCHY (TARGET): [14, 17, 19, 5, 12, 17, 20, 12, 24, 0]\n",
      "\n",
      "OUT OF BATCHX:   [12 17 20 12  5 19 14 22 17  5] => [' ', 'i', 's', ' ', 'n', 'o', 't', 'h', 'i', 'n']\n",
      "BATCHY (TARGET): [12, 17, 20, 12, 5, 19, 14, 22, 17, 5]\n",
      "\n",
      "OUT OF BATCHX:   [14 19 14 22 17  5  1 12 10 19] => ['t', 'o', 't', 'h', 'i', 'n', 'g', ' ', 'm', 'o']\n",
      "BATCHY (TARGET): [5, 19, 14, 22, 17, 5, 1, 12, 10, 19]\n",
      "\n",
      "OUT OF BATCHX:   [12  5  8 14 12  3 22 16  5 12] => [' ', 'n', 'u', 't', ' ', 'w', 'h', 'e', 'n', ' ']\n",
      "BATCHY (TARGET): [12, 9, 8, 14, 12, 3, 22, 16, 5, 12]\n",
      "\n",
      "OUT OF BATCHX:   [14 19 14 22 17  5  1 12 10 19] => ['t', 'o', 't', 'h', 'i', 'n', 'g', ' ', 'm', 'o']\n",
      "BATCHY (TARGET): [5, 19, 14, 22, 17, 5, 1, 12, 10, 19]\n",
      "\n",
      "OUT OF BATCHX:   [14 12 14 19 12 14 24  4 16 12] => ['t', ' ', 't', 'o', ' ', 't', 'a', 'k', 'e', ' ']\n",
      "BATCHY (TARGET): [14, 12, 14, 19, 12, 14, 24, 4, 16, 12]\n",
      "\n",
      "OUT OF BATCHX:   [18 18 12  9  8 14 12  3 22 16] => [',', ',', ' ', 'b', 'u', 't', ' ', 'w', 'h', 'e']\n",
      "BATCHY (TARGET): [15, 18, 12, 9, 8, 14, 12, 3, 22, 16]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "randidx = np.random.randint(low=0, high=ndata, size=batch_size)\n",
    "batchX = [dataX[iii] for iii in randidx]\n",
    "batchY = [dataY[iii] for iii in randidx]\n",
    "feeds = {X: batchX}\n",
    "results = sess.run(outputs, feed_dict=feeds)\n",
    "for j, result in enumerate(results):\n",
    "    index = np.argmax(result, axis=1)\n",
    "    chars = [char_set[t] for t in index]\n",
    "    if j < 10:\n",
    "        print (\"OUT OF BATCHX:   %s => %s\" % (index, chars))\n",
    "        print (\"BATCHY (TARGET): %s\\n\" % (batchY[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAMPLING FUNCTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XL    LOOKS LIKE Tensor(\"Placeholder_2:0\", shape=(?, 1), dtype=int32)\n",
      "XL_OH LOOKS LIKE Tensor(\"one_hot_1:0\", shape=(?, 1, 25), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "LEN = 1 # <= LENGHT IS 1 !!\n",
    "# XL = tf.placeholder(tf.int32, [None, LEN])\n",
    "XL     = tf.placeholder(tf.int32, [None, 1])\n",
    "XL_OH  = tf.one_hot(XL, num_classes)\n",
    "with tf.variable_scope('CHAR-RNN', reuse=True):\n",
    "    cell_L = rnn.BasicLSTMCell(hidden_size, state_is_tuple=True, reuse=True)\n",
    "    # cell_L = rnn.MultiRNNCell([cell_L] * 2, state_is_tuple=True) # BUG IN TF1.1\n",
    "    istate = cell_L.zero_state(batch_size=1, dtype=tf.float32)\n",
    "    # DYNAMIC RNN WITH FULLY CONNECTED LAYER\n",
    "    _hiddens  = tf.contrib.layers.fully_connected(XL_OH, hidden_size, activation_fn=tf.nn.relu)\n",
    "    _outputs_L, states_L = tf.nn.dynamic_rnn(cell_L, _hiddens\n",
    "                                , initial_state=istate, dtype=tf.float32)\n",
    "    _outputs_L  = tf.contrib.layers.fully_connected(\n",
    "        _outputs_L, num_classes, activation_fn=None)\n",
    "    # RESHAPE FOR SEQUNCE LOSS\n",
    "    outputs_L = tf.reshape(_outputs_L, [LEN, 1, num_classes])\n",
    "print (\"XL    LOOKS LIKE %s\" % (XL))\n",
    "print (\"XL_OH LOOKS LIKE %s\" % (XL_OH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HELPER FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_pick(weights):\n",
    "    t = np.cumsum(weights)\n",
    "    s = np.sum(weights)\n",
    "    return(int(np.searchsorted(t, np.random.rand(1)*s)))\n",
    "def softmax(x):\n",
    "    alpha = 1\n",
    "    e_x = np.exp(alpha*(x - np.max(x)))\n",
    "    return e_x / np.sum(e_x) # only difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BURNIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] -char:  P \n",
      "    -inval: [[23]] \n",
      "    -outval: [[[ -8.083251    -2.7365427   -0.01721089  -2.7928133   -5.45727015\n",
      "    -1.01345122  -6.01259851  -7.22651958  -3.13926625  -4.29166126\n",
      "     0.14808631  -3.7139504   -2.8849721    0.78088862   2.98004508\n",
      "    -1.75051367  12.91055012   4.83504868   1.53668344   3.67999387\n",
      "    -2.49500585   2.41470742   0.64288658  -3.25742102  -2.91963959]]] \n",
      "[1] -char:  e \n",
      "    -inval: [[16]] \n",
      "    -outval: [[[  5.01418829  -4.0058651    0.82219779  -3.44058609  -1.45845723\n",
      "     5.68695116   0.26826409   4.01365089   0.33876163  -2.19759774\n",
      "    -0.4963997   -1.81084132  -1.04217005   6.27676249   0.88501585\n",
      "     4.29535723   1.94310606  -4.77040052   1.35450602  -3.10625553\n",
      "    -3.33001232  13.49173737  -5.49444437  -0.9884336   -5.6234827 ]]] \n",
      "[2] -char:  r \n",
      "    -inval: [[21]] \n",
      "    -outval: [[[  1.61779118  -5.15967894  -2.1306777   -5.99924803  -3.75904703\n",
      "    -2.36696339  -5.14207602   1.05601883  -0.43575048  -8.57248592\n",
      "    -2.89001083  -1.14938211   2.32331014  16.08016396   3.49251938\n",
      "     3.21207333   9.25331879   2.06688976   1.89102006  -3.24270034\n",
      "    -4.89881897   0.91650367  -2.49564004  -1.08529842  -6.99518728]]] \n"
     ]
    }
   ],
   "source": [
    "prime = \"Perfection is\"\n",
    "istateval = sess.run(cell_L.zero_state(1, tf.float32))\n",
    "for i, c in enumerate(prime[:-1]):\n",
    "    index = char_dic[c]\n",
    "    inval = [[index]]\n",
    "    outval, stateval = sess.run([outputs_L, states_L]\n",
    "                        , feed_dict={XL:inval, istate:istateval})\n",
    "    istateval = stateval # UPDATE STATE MANUALLY!!\n",
    "    if i < 3:\n",
    "        print (\"[%d] -char:  %s \\n    -inval: %s \\n    -outval: %s \" \n",
    "               % (i, c, inval, outval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \n",
      " -inval: [[12]] \n",
      " -outval: [[[  0.67843425  -2.08114338  -0.32877958  -0.71623373  -6.46169662\n",
      "     7.21603251  -2.14627552  -8.24349689  -4.73580694   3.33558416\n",
      "     0.40434808  -1.73716736   5.20630836  -9.15944004   1.35718107\n",
      "    -1.93660891  -5.90542173   5.69831371  -0.3494606   -1.54447627\n",
      "     1.23852599  -7.73629093   1.7253958   -4.76701975  15.29266071]]] \n",
      " -index: 24 (char: a) \n",
      " -chars:  a\n",
      "[1] \n",
      " -inval: [[24]] \n",
      " -outval: [[[ 16.70030785  -5.62605572  -2.07418704   2.41097379  -3.50659609\n",
      "     2.73988485   1.72936344  -5.1719346    0.9869777   -0.10085863\n",
      "    -2.83843112  -1.2794956    0.10418161  -6.61042643   0.0844142\n",
      "     6.4254899   -9.78278923  -2.84867382  -1.83677375   1.13077807\n",
      "     5.24185658  -2.07052469   3.12206078  -0.57869923   4.67526865]]] \n",
      " -index: 0 (char: c) \n",
      " -chars:  ac\n",
      "[2] \n",
      " -inval: [[0]] \n",
      " -outval: [[[ -0.03909219  -4.75933599  -3.95792174  -3.53075409  -7.28938055\n",
      "    -1.10193872  -5.83994722 -12.79705906   0.78332967  -0.74953425\n",
      "    -4.15386534  -6.48967361   4.67089987  -3.44457436   5.26709032\n",
      "    -1.06033742  -4.39459467   2.16232133  -3.29977918   4.42601204\n",
      "    -3.64857984  -1.45731163  16.68020439  -2.51001406   6.23244762]]] \n",
      " -index: 22 (char: h) \n",
      " -chars:  ach\n",
      "[3] \n",
      " -inval: [[22]] \n",
      " -outval: [[[ -6.46543312  -4.37965441  -4.43681669   1.80711055   0.81891507\n",
      "    -4.19609308  -6.37573624 -13.95327473  -0.35125944  -3.3966589\n",
      "    -3.30588102  -1.44966948   0.40442973   0.56563532   3.41654825\n",
      "    -3.89797926   7.71994543  17.60820007   0.3524746   -1.58875263\n",
      "    -7.65214825  -4.18829012   5.4741869   -3.35573292   3.99988699]]] \n",
      " -index: 17 (char: i) \n",
      " -chars:  achi\n",
      "[4] \n",
      " -inval: [[17]] \n",
      " -outval: [[[ -9.07173443  -0.52926236  -1.77333128   0.31875116   0.17449796\n",
      "     2.89828444  -3.72008181  -0.23122409  -0.20478579  -3.47570658\n",
      "    -0.88748366   0.08597946  -3.15704894   0.380514    -3.39481783\n",
      "    -3.27684975  13.89799881   3.54209304  -2.1522131    3.37175775\n",
      "     0.15042967   0.54695004  -3.29270506  -4.15860558  -0.93315011]]] \n",
      " -index: 16 (char: e) \n",
      " -chars:  achie\n"
     ]
    }
   ],
   "source": [
    "inval  = [[char_dic[prime[-1]]]]\n",
    "outval, stateval = sess.run([outputs_L, states_L]\n",
    "                    , feed_dict={XL:inval, istate:istateval})\n",
    "istateval = stateval\n",
    "index = np.argmax(outval)\n",
    "char  = char_set[index]\n",
    "chars = char\n",
    "for i in range(100):\n",
    "    inval = [[index]]\n",
    "    outval, stateval = sess.run([outputs_L, states_L]\n",
    "                        , feed_dict={XL:inval, istate:istateval})\n",
    "    istateval = stateval\n",
    "    # index = np.argmax(outval)\n",
    "    index = weighted_pick(softmax(outval))\n",
    "    char  = char_set[index]\n",
    "    chars += char\n",
    "    if i < 5:\n",
    "        print (\"[%d] \\n -inval: %s \\n -outval: %s \\n -index: %d (char: %s) \\n -chars: %s\" \n",
    "               % (i, inval, outval, index, char, chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAMPLED SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SAMPLED SETENCE> \n",
      " Perfection is achieved, not when there is nothing more to add, but when there is nothing more to add, but when the\n",
      "\n",
      "<ORIGINAL SENTENCE> \n",
      " Perfection is achieved, not when there is nothing more to add, but when there is nothing left to take away.\n"
     ]
    }
   ],
   "source": [
    "print (\"<SAMPLED SETENCE> \\n %s\" % (prime+chars))\n",
    "print (\"\\n<ORIGINAL SENTENCE> \\n %s\" % (sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test complete; Gopal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
