{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Generative Adversarial Networks\n",
    "\n",
    "In [deep convolutional generative adversarial networks (DCGAN)](./dcgan.ipynb), \n",
    "we introduced how to generate human face images from random noise. With a DCGAN, we can generate images from random vectors, but what kind of images do we achieve? Can we specify it is a woman or man face?\n",
    "\n",
    "In this notebook, we introduce [conditional GAN](https://arxiv.org/abs/1411.1784), which accepts label as part of the input for both generator and discriminator. With conditional GAN, you can choose which kind of data to generate with corresponding label. We'll train on MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "Using TensorFlow backend.\n",
      "/srv/conda/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gopala KR \n",
      "last updated: 2018-03-01 \n",
      "\n",
      "CPython 3.6.4\n",
      "IPython 6.2.1\n",
      "\n",
      "watermark 1.6.0\n",
      "numpy 1.14.1\n",
      "matplotlib 2.1.2\n",
      "nltk 3.2.5\n",
      "sklearn 0.19.1\n",
      "tensorflow 1.5.0\n",
      "theano 1.0.1\n",
      "mxnet 1.2.0\n",
      "chainer 3.4.0\n",
      "seaborn 0.8.1\n",
      "keras 2.1.4\n",
      "tflearn n\u0007\n",
      "bokeh 0.12.14\n",
      "gensim 3.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/lib/python3.6/site-packages/scipy/sparse/sparsetools.py:20: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "#load watermark\n",
    "%load_ext watermark\n",
    "%watermark -a 'Gopala KR' -u -d -v -p watermark,numpy,matplotlib,nltk,sklearn,tensorflow,theano,mxnet,chainer,seaborn,keras,tflearn,bokeh,gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/srv/conda/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, test_utils, autograd\n",
    "from mxnet import ndarray as nd\n",
    "from mxnet.gluon import nn, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "label_size = 10\n",
    "latent_z_size = 100\n",
    "hidden_units = 128\n",
    "img_wd = 28\n",
    "img_ht = 28\n",
    "\n",
    "use_gpu = True\n",
    "ctx = mx.gpu() if use_gpu else mx.cpu()\n",
    "\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and preprocess the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/lib/python3.6/site-packages/mxnet/test_utils.py:1434: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  label = np.fromstring(flbl.read(), dtype=np.int8)\n",
      "/srv/conda/lib/python3.6/site-packages/mxnet/test_utils.py:1437: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  image = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(label), rows, cols)\n"
     ]
    }
   ],
   "source": [
    "# Pixel values of mnist image are normalized to be from 0 to 1.\n",
    "mnist_data = test_utils.get_mnist()\n",
    "train_data = mnist_data['train_data']\n",
    "train_label = nd.one_hot(nd.array(mnist_data['train_label']), 10)\n",
    "train_iter = mx.io.NDArrayIter(data=train_data, label=train_label, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize 4 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(img_arr):\n",
    "    plt.imshow((img_arr.asnumpy().reshape(img_wd, img_ht) * 255).astype(np.uint8), cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    visualize(nd.array(train_data[i + 10]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the networks\n",
    "\n",
    "Input of generator is the concatenation of random noise vector and digit label one hot vector. It is followed by a fully connected layer and relu activation function. Output layer is composed by another fully connected layer and sigmoid activation function.\n",
    "\n",
    "Similar to generator, input of discriminator is the concatenation of flatten image vector and digit label. It is followed by a fully connected layer and relu activation function. Output layer is composed by another fully connected layer and sigmoid activation function. In this tutorial we don't apply sigmoid function to output to make training process more numerically stable.\n",
    "\n",
    "![](../img/cgan.png \"Conditional GAN Architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_init = mx.init.Xavier()\n",
    "\n",
    "# Build the generator\n",
    "netG = nn.HybridSequential()\n",
    "with netG.name_scope():\n",
    "    netG.add(nn.Dense(units=hidden_units, activation='relu', weight_initializer=w_init))\n",
    "    netG.add(nn.Dense(units=img_wd * img_ht, activation='sigmoid', weight_initializer=w_init))\n",
    "\n",
    "# Build the discriminator\n",
    "netD = nn.HybridSequential()\n",
    "with netD.name_scope():\n",
    "    netD.add(nn.Dense(units=hidden_units, activation='relu', weight_initializer=w_init))\n",
    "    netD.add(nn.Dense(units=1, weight_initializer=w_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Loss Function and Optimizer\n",
    "We use binary cross-entropy as our loss function and use the Adam optimizer. We initialize the network's parameters by sampling from a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "loss = gluon.loss.SigmoidBinaryCrossEntropyLoss()\n",
    "\n",
    "# Initialize the generator and the discriminator\n",
    "netG.initialize(ctx=ctx)\n",
    "netD.initialize(ctx=ctx)\n",
    "\n",
    "# Trainer for the generator and the discriminator\n",
    "trainerG = gluon.Trainer(netG.collect_params(), 'adam', {'learning_rate': lr})\n",
    "trainerD = gluon.Trainer(netD.collect_params(), 'adam', {'learning_rate': lr})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "We recommend that you use a GPU for training this model. After a few epochs, we can see human-face-like images are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "import logging\n",
    "\n",
    "real_label = nd.ones((batch_size,), ctx=ctx)\n",
    "fake_label = nd.zeros((batch_size,),ctx=ctx)\n",
    "\n",
    "def facc(label, pred):\n",
    "    pred = pred.ravel()\n",
    "    label = label.ravel()\n",
    "    return ((pred > 0.5) == label).mean()\n",
    "metric = mx.metric.CustomMetric(facc)\n",
    "\n",
    "stamp =  datetime.now().strftime('%Y_%m_%d-%H_%M')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    tic = time.time()\n",
    "    btic = time.time()\n",
    "    train_iter.reset()\n",
    "    iter = 0\n",
    "    for batch in train_iter:\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        data = batch.data[0].as_in_context(ctx)\n",
    "        label = batch.label[0].as_in_context(ctx)\n",
    "        latent_z = mx.nd.random_normal(0, 1, shape=(batch_size, latent_z_size), ctx=ctx)\n",
    "        D_input = nd.concat(data.reshape((data.shape[0], -1)), label)\n",
    "        G_input = nd.concat(latent_z, label)\n",
    "\n",
    "        with autograd.record():\n",
    "            # train with real image\n",
    "            output = netD(D_input)\n",
    "            errD_real = loss(output, real_label)\n",
    "            metric.update([real_label,], [output,])\n",
    "\n",
    "            # train with fake image\n",
    "            fake = netG(G_input)\n",
    "            D_fake_input = nd.concat(fake.reshape((fake.shape[0], -1)), label)\n",
    "            output = netD(D_fake_input.detach())\n",
    "            errD_fake = loss(output, fake_label)\n",
    "            errD = errD_real + errD_fake\n",
    "            errD.backward()\n",
    "            metric.update([fake_label,], [output,])\n",
    "\n",
    "        trainerD.step(batch.data[0].shape[0])\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        with autograd.record():\n",
    "            fake = netG(G_input)\n",
    "            D_fake_input = nd.concat(fake.reshape((fake.shape[0], -1)), label)\n",
    "            output = netD(D_fake_input)\n",
    "            errG = loss(output, real_label)\n",
    "            errG.backward()\n",
    "\n",
    "        trainerG.step(batch.data[0].shape[0])\n",
    "\n",
    "        # Print log infomation every ten batches\n",
    "        if iter % 10 == 0:\n",
    "            name, acc = metric.get()\n",
    "            logging.info('speed: {} samples/s'.format(batch_size / (time.time() - btic)))\n",
    "            logging.info('discriminator loss = %f, generator loss = %f, binary training acc = %f at iter %d epoch %d' \n",
    "                     %(nd.mean(errD).asscalar(), \n",
    "                       nd.mean(errG).asscalar(), acc, iter, epoch))\n",
    "        iter = iter + 1\n",
    "        btic = time.time()\n",
    "\n",
    "    name, acc = metric.get()\n",
    "    metric.reset()\n",
    "    logging.info('\\nbinary training acc at epoch %d: %s=%f' % (epoch, name, acc))\n",
    "    logging.info('time: %f' % (time.time() - tic))\n",
    "\n",
    "    # Visualize one generated image for each epoch\n",
    "    fake_img = fake[0]\n",
    "    visualize(fake_img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Given a trained generator, we can generate some images of digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_image = 4\n",
    "for digit in range(10):\n",
    "    for i in range(num_image):\n",
    "        latent_z = mx.nd.random_normal(0, 1, shape=(1, latent_z_size), ctx=ctx)\n",
    "        label = nd.one_hot(nd.array([[digit]]), 10).as_in_context(ctx)\n",
    "        img = netG(nd.concat(latent_z, label.reshape((1, 10))))\n",
    "        plt.subplot(10, 4, digit * 4 + i + 1)\n",
    "        visualize(img[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For whinges or inquiries, [open an issue on  GitHub.](https://github.com/zackchase/mxnet-the-straight-dope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
